{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9768ce8f",
   "metadata": {},
   "source": [
    "# 4. Training and evaluating the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb827546",
   "metadata": {},
   "source": [
    "## 4.1. Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f2d95e",
   "metadata": {},
   "source": [
    "### 4.1.1. Parent model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712dc5ba",
   "metadata": {},
   "source": [
    "After the previous step we ended up with folder \"prepared\" with prepared data for the model. Our next step will be training the model. I used 2 GPUs so this was the training command I ran:\n",
    "```bash\n",
    "torchrun --no_python --nproc_per_node 2 sockeye-train \\\n",
    "    --output model \\\n",
    "    --decode-and-evaluate -1 \\\n",
    "    --checkpoint-interval 4000 \\\n",
    "    --gradient-clipping-type abs \\\n",
    "    --initial-learning-rate 0.0001 \\\n",
    "    --keep-last-params 2 \\\n",
    "    --batch-size 8192 \\\n",
    "    --max-seq-len 200 \\\n",
    "    --num-layers 6 \\\n",
    "    --weight-tying none \\\n",
    "    --max-num-epochs 10000 \\\n",
    "    --optimized-metric bleu \\\n",
    "    --prepared-data prepared \\\n",
    "    --validation-source=dev_file.BPE.de \\\n",
    "    --validation-target=dev_file.BPE.cs \\\n",
    "    --dist \\\n",
    "    --quiet-secondary-workers\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2609520d",
   "metadata": {},
   "source": [
    "### 4.1.2. Child model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82eed1b3",
   "metadata": {},
   "source": [
    "As a result of this command we get a \"model\" folder with the weights. This folder (in particular, best weights from it) we mention in a training command for child model. I trained child model on 1 GPU so this was the command:\n",
    "```bash\n",
    "sockeye-train \\\n",
    "    --output dehsb_model \\\n",
    "    --params model/params.best \\\n",
    "    --decode-and-evaluate -1 \\\n",
    "    --checkpoint-interval 4000 \\\n",
    "    --gradient-clipping-type abs \\\n",
    "    --initial-learning-rate 0.0001 \\\n",
    "    --keep-last-params 2 \\\n",
    "    --batch-size 8192 \\\n",
    "    --max-seq-len 200 \\\n",
    "    --num-layers 6 \\\n",
    "    --weight-tying none \\\n",
    "    --max-num-epochs 10000 \\\n",
    "    --optimized-metric bleu \\\n",
    "    --prepared-data prepared_child \\\n",
    "    --validation-source devel.hsb-de.BPE.de \\\n",
    "    --validation-target devel.hsb-de.BPE.hsb\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4e6cb0",
   "metadata": {},
   "source": [
    "## 4.2. Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc526a2",
   "metadata": {},
   "source": [
    "In order to evaluate the model we need to translate the sentences from the test set (those that model didn't see during training) and then compare them to the reference translation. This is command for translating:\n",
    "```bash\n",
    "sockeye-translate --input devel_test.hsb-de.de --output out.bpe --model dehsb_model --dtype float32 --beam-size 5 --batch-size 64\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675fcbf4",
   "metadata": {},
   "source": [
    "After that we get bask from tokenized lines to actual texts with this command:\n",
    "```bash\n",
    "sed -E 's/(@@ |@@$)//g' <out.bpe >out.tok\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72aec243",
   "metadata": {},
   "source": [
    "After that we use sacrebleu tool to check BLEU metric:\n",
    "```bash\n",
    "sacrebleu devel_test.hsb-de.hsb -tok none -i out.tok\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c040085",
   "metadata": {},
   "source": [
    "And ChrF metric:\n",
    "```bash\n",
    "sacrebleu devel_test.hsb-de.hsb --metrics chrf -i out.tok\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef9dfd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
